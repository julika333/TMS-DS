{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0mKUZgiH8ZW4T2+qtVcTT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julika333/TMS-DS/blob/main/lesson_25_tensor_and_pytorch/HW_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TensorFlow**\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "V8H2KNXd8lH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras-tuner"
      ],
      "metadata": {
        "id": "yC6_mLT78dEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from keras_tuner import RandomSearch, Hyperband"
      ],
      "metadata": {
        "id": "2JrkcjRd87tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "B-z8C8fR8_Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1tjDeeF8Ze7",
        "outputId": "1e0c72f3-a331-4d81-fc1f-85092424d2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 02m 23s]\n",
            "val_accuracy: 0.9792500138282776\n",
            "\n",
            "Best val_accuracy So Far: 0.9807500243186951\n",
            "Total elapsed time: 00h 19m 45s\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 384)               301440    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                3850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 305290 (1.16 MB)\n",
            "Trainable params: 305290 (1.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    # Hyperparameter tuning for the number of units in the hidden layer\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units, activation='relu'))\n",
        "\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # Hyperparameter tuning for the optimizer\n",
        "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
        "\n",
        "    model.compile(optimizer=hp_optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Random search tuner\n",
        "random_search_tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2,\n",
        "    directory='random_search_dir',\n",
        "    project_name='mnist_tuning')\n",
        "\n",
        "# Hyperband tuner\n",
        "hyperband_tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    directory='hyperband_dir',\n",
        "    project_name='mnist_tuning')\n",
        "\n",
        "# Train the models\n",
        "random_search_tuner.search(x_train, y_train, epochs=5, validation_split=0.2)\n",
        "hyperband_tuner.search(x_train, y_train, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Get the best model\n",
        "best_model = random_search_tuner.get_best_models(num_models=1)[0]\n",
        "best_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband_tuner.results_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDDpgB7j8b9r",
        "outputId": "c4867168-7aab-4126-960e-e9fc6ae3be5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in hyperband_dir/mnist_tuning\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 0017 summary\n",
            "Hyperparameters:\n",
            "units: 320\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 10\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0015\n",
            "Score: 0.9807500243186951\n",
            "\n",
            "Trial 0029 summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "optimizer: adam\n",
            "tuner/epochs: 10\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.9792500138282776\n",
            "\n",
            "Trial 0023 summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.9781666398048401\n",
            "\n",
            "Trial 0024 summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 10\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0023\n",
            "Score: 0.9781666398048401\n",
            "\n",
            "Trial 0016 summary\n",
            "Hyperparameters:\n",
            "units: 480\n",
            "optimizer: adam\n",
            "tuner/epochs: 10\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0014\n",
            "Score: 0.9779166579246521\n",
            "\n",
            "Trial 0014 summary\n",
            "Hyperparameters:\n",
            "units: 480\n",
            "optimizer: adam\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0010\n",
            "Score: 0.9758333563804626\n",
            "\n",
            "Trial 0015 summary\n",
            "Hyperparameters:\n",
            "units: 320\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0000\n",
            "Score: 0.9757500290870667\n",
            "\n",
            "Trial 0013 summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0004\n",
            "Score: 0.9741666913032532\n",
            "\n",
            "Trial 0025 summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 10\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0020\n",
            "Score: 0.9735833406448364\n",
            "\n",
            "Trial 0012 summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "optimizer: rmsprop\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0003\n",
            "Score: 0.9734166860580444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch**\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "atQ9Wj3oDiYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torch-summary optuna"
      ],
      "metadata": {
        "id": "kcq3iUKFDn83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import optuna\n",
        "from optuna.trial import TrialState"
      ],
      "metadata": {
        "id": "z8NpLG0hDrXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('.', train=False, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "cW2mdsFbDtEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "viDkaJHSU9E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, trial):\n",
        "        super(Net, self).__init__()\n",
        "        n_units = trial.suggest_int(\"n_units\", 32, 512)\n",
        "        self.fc1 = nn.Linear(28 * 28, n_units)\n",
        "        self.fc2 = nn.Linear(n_units, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return torch.log_softmax(x, dim=1)\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    model = Net(trial).to(device)\n",
        "\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    return accuracy\n",
        "\n",
        "# Use Optuna for hyperparameter optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Get the best trial\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"Best trial: {trial.values}\")\n",
        "print(f\"Best hyperparameters: {trial.params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyaZm8_wDw6k",
        "outputId": "79d3b33a-79d9-40f7-fa0f-13dc258210ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 21:20:44,297] A new study created in memory with name: no-name-d203bba5-202c-4fe1-a82b-873c82118b87\n",
            "[I 2024-05-23 21:21:54,973] Trial 0 finished with value: 0.8983 and parameters: {'n_units': 171, 'optimizer': 'SGD', 'lr': 0.0023356773941556976}. Best is trial 0 with value: 0.8983.\n",
            "[I 2024-05-23 21:23:04,060] Trial 1 finished with value: 0.9037 and parameters: {'n_units': 135, 'optimizer': 'SGD', 'lr': 0.0031119474959408664}. Best is trial 1 with value: 0.9037.\n",
            "[I 2024-05-23 21:24:13,011] Trial 2 finished with value: 0.2338 and parameters: {'n_units': 70, 'optimizer': 'SGD', 'lr': 2.0135904531693266e-05}. Best is trial 1 with value: 0.9037.\n",
            "[I 2024-05-23 21:25:23,392] Trial 3 finished with value: 0.765 and parameters: {'n_units': 370, 'optimizer': 'SGD', 'lr': 0.00020980772035515514}. Best is trial 1 with value: 0.9037.\n",
            "[I 2024-05-23 21:26:34,391] Trial 4 finished with value: 0.9726 and parameters: {'n_units': 263, 'optimizer': 'RMSprop', 'lr': 0.0010489875047035024}. Best is trial 4 with value: 0.9726.\n",
            "[I 2024-05-23 21:27:42,793] Trial 5 finished with value: 0.8028 and parameters: {'n_units': 335, 'optimizer': 'SGD', 'lr': 0.0003037254716842506}. Best is trial 4 with value: 0.9726.\n",
            "[I 2024-05-23 21:28:52,237] Trial 6 finished with value: 0.2495 and parameters: {'n_units': 380, 'optimizer': 'RMSprop', 'lr': 0.08512214790878983}. Best is trial 4 with value: 0.9726.\n",
            "[I 2024-05-23 21:30:02,286] Trial 7 finished with value: 0.9716 and parameters: {'n_units': 335, 'optimizer': 'Adam', 'lr': 0.00037607537270343546}. Best is trial 4 with value: 0.9726.\n",
            "[I 2024-05-23 21:31:17,806] Trial 8 finished with value: 0.955 and parameters: {'n_units': 80, 'optimizer': 'Adam', 'lr': 0.00244531333142126}. Best is trial 4 with value: 0.9726.\n",
            "[I 2024-05-23 21:32:30,158] Trial 9 finished with value: 0.9539 and parameters: {'n_units': 71, 'optimizer': 'Adam', 'lr': 0.0006731904910971024}. Best is trial 4 with value: 0.9726.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: [0.9726]\n",
            "Best hyperparameters: {'n_units': 263, 'optimizer': 'RMSprop', 'lr': 0.0010489875047035024}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Notebook\n",
        "\n",
        "# Install necessary packages\n",
        "# !pip install torch torchvision torchsummary optuna\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import optuna\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self, units):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dense1 = nn.Linear(28*28, units)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dense2 = nn.Linear(units, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Hyperparameter tuning for the number of units in the hidden layer\n",
        "    units = trial.suggest_int('units', 32, 512, step=32)\n",
        "    model = MNISTModel(units)\n",
        "\n",
        "    # Hyperparameter tuning for the optimizer\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
        "    optimizer = getattr(optim, optimizer_name.capitalize())(model.parameters(), lr=0.01)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training the model\n",
        "    model.train()\n",
        "    for epoch in range(5):\n",
        "        for batch in train_loader:\n",
        "            inputs, targets = batch\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Validation accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = correct / len(test_dataset)\n",
        "    return accuracy\n",
        "\n",
        "# Random search tuner\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Get the best model\n",
        "trial = study.best_trial\n",
        "best_units = trial.params['units']\n",
        "best_model = MNISTModel(best_units)\n",
        "\n",
        "# Summary of the best model\n",
        "summary(best_model, input_size=(1, 28, 28))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sHr2m-VCTnxM",
        "outputId": "6bdfa2cd-b03b-409c-83fa-f92196a6a891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 17393300.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 477323.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4386875.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5259671.11it/s]\n",
            "[I 2024-05-23 21:45:58,536] A new study created in memory with name: no-name-41cd7765-485b-4f8d-8d2f-395b69d8afe7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 21:47:14,318] Trial 0 finished with value: 0.8077 and parameters: {'units': 64, 'optimizer': 'adam'}. Best is trial 0 with value: 0.8077.\n",
            "[I 2024-05-23 21:48:51,806] Trial 1 finished with value: 0.101 and parameters: {'units': 384, 'optimizer': 'adam'}. Best is trial 0 with value: 0.8077.\n",
            "[W 2024-05-23 21:48:51,813] Trial 2 failed with parameters: {'units': 128, 'optimizer': 'sgd'} because of the following error: AttributeError(\"module 'torch.optim' has no attribute 'Sgd'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-11-317b8838e6be>\", line 48, in objective\n",
            "    optimizer = getattr(optim, optimizer_name.capitalize())(model.parameters(), lr=0.01)\n",
            "AttributeError: module 'torch.optim' has no attribute 'Sgd'\n",
            "[W 2024-05-23 21:48:51,814] Trial 2 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torch.optim' has no attribute 'Sgd'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-317b8838e6be>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Random search tuner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Get the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-317b8838e6be>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Hyperparameter tuning for the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0moptimizer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'Sgd'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7bSJ8OSzYsf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}